'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/configuration/auto-kill/','title':"Auto Kill",'content':"Automatically kill programs InGRAINd can execute various commands to react to certain events with minimum overhead.\nBecause events are not intercepted, merely observed by the eBPF probe, InGRAIN cannot block a program from executing a certain action.\nHowever, using the events pipeline to filter and execute commands, InGRAIN can react to events quickly and reliably without involving other processing components. This means you fundamentally cannot stop a task from executing, but long-running processes can be killed.\nYou can configure this behaviour by adding the Exec step to your pipeline:\n[[pipeline.s3.steps]] type = \u0026quot;Exec\u0026quot; arguments = [\u0026quot;kill\u0026quot;, \u0026quot;-9\u0026quot;, \u0026quot;{ process_id }\u0026quot;] only_if = [ { key = \u0026quot;some_key\u0026quot;, regex = \u0026quot;prefix.*\u0026quot; } ]  Monitoring a directory For example, to stop someone editing your SSH keys using Vim, you can use the following configuration:\n[[probe]] pipelines = [\u0026quot;console\u0026quot;] [probe.config] type = \u0026quot;files\u0026quot; monitor_dirs = [\u0026quot;/home/user\u0026quot;] [[pipeline.s3.steps]] type = \u0026quot;Exec\u0026quot; command = [\u0026quot;kill\u0026quot;, \u0026quot;-9\u0026quot;, \u0026quot;{ process_id }\u0026quot;] only_if = [ { key = \u0026quot;process_str\u0026quot;, regex = \u0026quot;.*vim\u0026quot; }, { key = \u0026quot;path_str\u0026quot;, regex = \u0026quot;.*.ssh/id_.*\u0026quot; }, ]  "});index.add({'id':1,'href':'/docs/configuration/backends/','title':"Backends",'content':""});index.add({'id':2,'href':'/docs/configuration/containers/','title':"Containers",'content':"Containers Monitoring containerised workloads is usually not an easy thing to do. With InGRAINd, you can get the ID of the Docker container that\u0026rsquo;s hosting the applications with simply including the following in the Container step in your pipeline.\n[[pipeline.console.steps]] type = \u0026quot;Container\u0026quot;  This will add the docker_id tag to each event that comes from a container, allowing you to link them to a running Docker container.\nSince Kubernetes is based on Docker, this also allows you to monitor workloads in Kubernetes clusters.\nFor instance, when a container is tagged like the following,\n\u0026quot;docker_id\u0026quot;: \u0026quot;c746bf8f9aadb4d5a3577fb67f34029c07c03607a4979779854dd59f373ef5b8\u0026quot;  You can gather information about it just by using the usual Docker CLI:\n$ docker inspect c746bf8f9aadb4d5a3577fb67f34029c07c03607a4979779854dd59f373ef5b8  "});index.add({'id':3,'href':'/docs/configuration/network/','title':"Network",'content':"Network monitoring The network monitoring grain in InGRAINd collects network events straight from the kernel, unlike most network monitoring solutions. Because of this, InGRAINd can observe detailed statistics about the network behaviour of applications without impacting network throughput and performance.\nEnabling network monitoring for all network interfaces, therefore, is as easy as enabling the Network probe in config.toml:\n[[probe]] pipelines = [\u0026quot;console\u0026quot;] [probe.config] type = \u0026quot;Network\u0026quot;  The grain monitors all outgoing connections from the box, and will print the details of outgoing connections:\n[{\u0026quot;timestamp\u0026quot;:1582294577893714161, \u0026quot;kind\u0026quot;:13, \u0026quot;name\u0026quot;:\u0026quot;connection.out_count\u0026quot;, \u0026quot;measurement\u0026quot;:1, \u0026quot;tags\u0026quot;:{\u0026quot;s_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;s_port\u0026quot;:\u0026quot;45719\u0026quot;, \u0026quot;d_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;process_id\u0026quot;:\u0026quot;4878\u0026quot;, \u0026quot;process_str\u0026quot;:\u0026quot;Socket Thread\u0026quot;, \u0026quot;d_port\u0026quot;:\u0026quot;1313\u0026quot;}}]  The details of an outbound and inbound traffic is also clearly visible, even on localhost:\n[{\u0026quot;timestamp\u0026quot;:1582294577893874264, \u0026quot;kind\u0026quot;:9, \u0026quot;name\u0026quot;:\u0026quot;volume.out_byte\u0026quot;, \u0026quot;measurement\u0026quot;:0, \u0026quot;tags\u0026quot;:{\u0026quot;d_port\u0026quot;:\u0026quot;1313\u0026quot;, \u0026quot;d_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;process_str\u0026quot;:\u0026quot;Socket Thread\u0026quot;, \u0026quot;s_port\u0026quot;:\u0026quot;45719\u0026quot;, \u0026quot;s_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;process_id\u0026quot;:\u0026quot;4878\u0026quot;, \u0026quot;proto\u0026quot;:\u0026quot;tcp\u0026quot;}}] [{\u0026quot;timestamp\u0026quot;:1582294577893943829, \u0026quot;kind\u0026quot;:9, \u0026quot;name\u0026quot;:\u0026quot;volume.in_byte\u0026quot;, \u0026quot;measurement\u0026quot;:72, \u0026quot;tags\u0026quot;:{\u0026quot;s_port\u0026quot;:\u0026quot;8453\u0026quot;, \u0026quot;d_port\u0026quot;:\u0026quot;38834\u0026quot;, \u0026quot;d_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;s_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;proto\u0026quot;:\u0026quot;tcp\u0026quot;, \u0026quot;process_str\u0026quot;:\u0026quot;hugo\u0026quot;, \u0026quot;process_id\u0026quot;:\u0026quot;34081\u0026quot;}}]  The value of measurement is in bytes, and every single read() and write() system call can be observed for UDP and TCP traffic.\n"});index.add({'id':4,'href':'/docs/configuration/syntax/','title':"Syntax",'content':"Configuration syntax The configuration format used by ingraind is TOML.\nThe primary goal of the configuration system is to set up the grains and the processing pipelines used by ingraind.\nThe TOML file has two sections: the probes, and the pipelines.\nProbes The probe array contains the configuration for the probes, and a single entry looks like this:\n[[probe]] pipelines = [\u0026quot;my_pipeline\u0026quot;, \u0026quot;another_pipeline\u0026quot;] [probe.config] type = \u0026quot;Files\u0026quot; monitor_dirs = [\u0026quot;/\u0026quot;] The probe has to specify a list of pipelines that will receive its data. The probe.config section configures the probe itself; the type attribute is mandatory, anything else is probe dependent.\nThe different brackets in [[probe]] and [probe.config] are intentional: [[probe]] means a new entry in the probe array, while [probe.config] means \u0026ldquo;the config attribute of the probe\u0026rdquo;.\nPipelines The pipelines are named sequences of actions. Some steps in the pipeline will have state, so be aware that multiple probes targeting the pipeline with the same name, will use the same instance of the pipeline.\nConfiguration of pipelines looks like this:\n[pipeline.my_pipeline.config] backend = \u0026quot;StatsD\u0026quot; use_tags = true [[pipeline.statsd.steps]] type = \u0026quot;Whitelist\u0026quot; allow = [\u0026quot;k1\u0026quot;, \u0026quot;k2\u0026quot;] [[pipeline.statsd.steps]] type = \u0026quot;AddSystemDetails\u0026quot; [[pipeline.statsd.steps]] type = \u0026quot;Buffer\u0026quot; interval_s = 30 The distinction between the [pipeline.statsd.config] and [[pipeline.statsd.steps]] are the same as previously.\nEvents generated by the probe will hit the first step in the pipeline. Steps are defined in sequence, and events will trickle through every step, unless they are filtered out.\nThe pipeline.name.config.backend specifies which backend is used to transmit or store the events after every step in the pipeline is complete, and is a mandatory attribute. Other attributes in the pipeline.name.config section are dependent on the given backend.\n"});index.add({'id':5,'href':'/docs/deployment/ansible/','title':"Ansible",'content':"Ansible InGRAINd provides Ansible roles in the repository that you can lift and integrate into your deployment systems.\nThe role installs OSQuery by default on compatible systems, which means you can use the InGRAINd - OSQuery bridge to gather a wide range of system statistics using a single configuration file.\nConfiguration To keep configuration as simple as possible, the role relies on the following variables:\ningraind_circleci_url ingraind_circleci_sha256 ingraind_http_api_key ingraind_http_uri  By default the agent will send events to an HTTP backend periodically.\nSystemD The Ansible role, by default, deploys a SystemD service file and configures it to use the configuration location for /etc/ingraind/ingraind.toml.\nKeeping up-to-date To keep InGRAINd up-to-date, we will reference the URL and hash of the latest stable release in the repository\u0026rsquo;s variables file, so you can synchronise the role and override the default variables in your deployment.\n"});index.add({'id':6,'href':'/docs/deployment/kubernetes/','title':"Kubernetes",'content':"Kubernetes Monitoring a Kubernetes cluster is easy based on the YAML files that are in the InGRAINd repository.\nYou can use the following containers built from the InGRAINd releases for various platforms:\n latest-gke: Google Container Optimized OS (COS) latest-amzn2: Amazon Linux 2 latest-fedora31: Fedora 31 latest-elrepo8: CentOS8/Epel latest-elrepo7: CentOS7/Epel  For deploying InGRAINd on Google Kubernetes Engine, use the latest-gke flavor, targeting Container Optimized OS (COS).\nWhen using Amazon Elastic Kubernetes Service (EKS), use latest-amzn2, which also works on Amazon Linux VMs as a privileged Docker container.\nInGRAINd requires access to system folders and eBPF-related system calls, therefore it needs to run as a privileged container.\nTo deploy InGRAINd on Kubernetes, adjust the ingraind.yaml file with the correct flavor of the containers for your host operating system, and use the usual deployment ritual:\nkubectl apply -f config.yaml kubectl apply -f ingraind.yaml  Refer to the pages on [configuration](LINK TODO) and the example config.toml for fine-tuning config.yaml.\n"});index.add({'id':7,'href':'/docs/deployment/strategies/','title':"Strategies",'content':"Deployment Strategies The best deployment strategy for your environment depends on a few factors. Whether you want to monitor containers, the orchestration service you\u0026rsquo;re running, and the amount of automation you already have, there are a few routes to go.\nAn abundance of containers To monitor containers across your fleet, you can use the native Kubernetes support. This comes packaged suitable for your environment and there\u0026rsquo;s no need to install drivers or kernel modules if you\u0026rsquo;re on one of the big cloud providers.\nA fleet of VMs To provision InGRAINd as part of your VM fleet, or Packer images, you\u0026rsquo;re best off taking inspiration from the Ansible rules, or using the integrations.\nAnsible integrates neatly with both Packer and Terraform through their modular environments.\n"});index.add({'id':8,'href':'/docs/devel/internals/','title':"Internals",'content':"How it all works Build Build starts with build.rs going through all modules in the bpf/ directory, and:\n Compile all .c files with clang into BPF bytecode. Run bindgen for all structs, the names of which start with _data_ (e.g. _data_tcp_connect).  bpf_helpers.h is in the include directory, so bindgen can be run freely on all .h files under bpf/. This is quirky, but works.\nThe produced BPF bytecode ELF packages are embedded in the final binary using include_bytes! statements. The produced bindings are embedded using include! statements.\nRuntime Grains are self-contained monitors and reporters. Each grain can gather their own type of statistics about a particular aspect of the system\u0026rsquo;s operation. Grains need to manage any BPF modules they might be using. Every grain is coupled with a dedicated cloud-based analytics backend.\nBPF probes are using the kernel\u0026rsquo;s eBPF virtual machine to execute a safe bytecode directly in kernel-space. These modules can only interact with the outside world using well-defined interfaces, and cannot execute arbitrary system calls.\nThe BPF modules will send data to userland using perf_event ring-buffers. These ring-buffers are fixed size buffers with a size multiples of the platform native VMM page size (4k on x86/x64).\nImportant to note 2 things:\n The license of BPF modules needs to be GPL is we want to extract data from the kernel into userland through the perf_event interface. If the module\u0026rsquo;s version does not match the running kernel\u0026rsquo;s version number, the kernel will refuse to load the module. The workaround here is using 0xFFFFFFFE in the binary to stay compatible with gobpf. This version will be replaced runtime by redbpf.  After the BPF probes are parsed from the ELF files, the following syscalls are made, in order:\n bpf_create_map: All global data is stored in maps. These structures are allocated during parsing. bpf_prog_load: Load a program into the BPF VM, and initialise it bpf_attach_kprobe: Attach BPF probes to a syscall. Entry probes and return probes are possible, they will be called when entering or exiting a syscall, respectively. bpf_update_elem: the perf_event ringbuffers are initialised. This includes allocating a perf_reader object, which are used for userspace consumption of the bpf_perf_event_output calls in the probes.  Perf Events Ingraind uses the perf_event_open (2) interface to communicate with the kernel\u0026rsquo;s BPF VM.\nThe BPF modules will access the perf_event ring buffers through a BPF_MAP structure of type BPF_MAP_PERF_EVENT_ARRAY. The maps contain an fd that is keyed by the CPU id. Technically, multiple strategies are allowed for keying this map, but the most popular looks like setting up a separate ring buffer for every online single CPU.\nEvents are consumed using an epoll_wait loop, and read until exhaustion. The benefit of a single epoll_wait loop is that all the complex logic behind initialisation of different grains ultimately ends up allowing notifications through a single fd, including all network, and even perf_event buffers.\nELF parsing A thing to note here before I get into this, is how state is managed in the BPF VM. There\u0026rsquo;s no global state allowed, so anything that needs to be persisted between calls into the probe needs to go through BPF_MAP_.* structures through VM opcodes (#define'd as function calls, eg. update, delete, etc.).\nA corollary to this is that global state used in the C source code is stored in the ELF binary in named PROGBITS sections, then loaded and initialised to be BPF_MAPs by the loader as data. We load this into memory, treating it as configuration, then instruct the kernel to set up global state storage to get an fd in return. This fd can also be used to send data back and forth between kernel- and userspace in certain cases.\nIt gets interesting when these are referenced in code (functions). The compiler generates a REL section that links to the symbol table, and has an info field that is a link to the amended section of code. The offset field specifies the offset in bytes from the start of the section that needs to be modified. A relocation, strictly in the BPF context, is a rewrite instruction for a specific instruction, in a specific section, referencing a specific symbol.\nBecause data access is always through VM opcodes, the instruction at the offset location is\u0026hellip; something. We don\u0026rsquo;t actually care. Relocations tell us to\u0026hellip; do something with it.\nWe need to rewrite the instruction\u0026rsquo;s source register (src_reg) with BPF_PSEUDO_MAP_FD, and the immediate constant parameter (imm) with the fd of the map that\u0026rsquo;s referenced by the symbol.\nSo to recap, this is the workflow to deal with loading ELF files:\n Load the strings table Load the symbol table Parse all the sections Create BPF_MAPs from the maps/ sections to acquire fds Go through all code sections, and apply relocations such that:  Resolve all REL symbols into fds (through the symbol table and back again). Rewrite the instruction at specified offset    "});index.add({'id':9,'href':'/docs/devel/performance/','title':"Performance",'content':"Performance The following measurements were done on an 8-core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz, Arch Linux, and ingraind @ 43281a7.\nThe following command will produce the raw output:\ncargo build --release \u0026amp;\u0026amp; \\ sudo AWS_ACCESS_KEY_ID=x \\ AWS_SECRET_ACCESS_KEY=x \\ AWS_BUCKET=x \\ AWS_INTERVAL=30 \\ DNS_IF=wlp61s0 \\ RUST_BACKTRACE=1 ./target/release/ingraind \u0026amp; sleep 5 \\ \u0026amp;\u0026amp; (top -b -d 2 |grep ingraind) \u0026gt;top_log \u0026amp; \\ iperf3 -t 10 -b 10M -c localhost \u0026gt; iperf_log \\ \u0026amp;\u0026amp; sleep 1 \u0026amp;\u0026amp; iperf3 -t 10 -b 100M -c localhost \u0026gt;\u0026gt;iperf_log \\ \u0026amp;\u0026amp; sleep 1 \u0026amp;\u0026amp; iperf3 -t 10 -b 1000M -c localhost \u0026gt;\u0026gt;iperf_log \\ \u0026amp;\u0026amp; sleep 1 \u0026amp;\u0026amp; iperf3 -t 10 -b 10000M -c localhost \u0026gt;\u0026gt;iperf_log \\ \u0026amp;\u0026amp; pkill top \\ \u0026amp;\u0026amp; @ pkill ingraind  Looking through the logs, we can see that CPU use follows bandwidth:\n   Bandwidth CPU %     10M 1%   100M 4%   1000M 32%   10000M 98%    This is test only measures the TCPv4 throughput of the one process, but gives a good idea about scaling.\n"});index.add({'id':10,'href':'/docs/devel/profiling/','title':"Profiling",'content':"Profiling During development The recommended way to profile ingraind binaries is using perf. The default --release builds are not stripped, therefore it should be easy to analyse the results.\nsudo perf record ./target/release/ingraind sudo perf report  Docker If running in a container, the recommended way is to start ingraind, then attach perf, and look the results off the box.\nsudo docker run -d --name ingraind -e OPTION=value [...] --pid=host --net=host --privileged ingraind sudo perf record -a -p `pgrep ingraind`  Looking at the results in this scenario is a bit tricky, because we will need to tell perf where the binaries are located to resolve the symbols.\nThis can be done by starting an ingraind container on the box that we\u0026rsquo;re using for analysis (if different from the system where we collected the data), then using the merged overlay filesystem as a base for symbol resolution. Note, you will need to use the same container version, as the symbols will change between builds.\nThis can be easily done like so:\nexport VERSION=sha256_of_profiled_container docker run -d --rm --name ingraind -it ingraind:$VERSION /bin/sh export CONTAINER_HASH=$(docker inspect ingraind |grep MergedDir |sed 's;.*: \u0026quot;\\(.*\\)\u0026quot;,;\\1;') sudo perf report -f -i perf.data_docker --symfs /var/lib/docker/overlay2/$CONTAINER_HASH/merged  After you\u0026rsquo;re done, you can shut down the container.\ndocker stop ingraind  Stat To get detailed stats about the execution of ingraind, you can perf stat like so:\n$ perf stat -a -p `pgrep ingraind` Performance counter stats for process id '28037': 3593.405601 cpu-clock (msec) # 0.114 CPUs utilized 147,307 context-switches # 0.041 M/sec 1,611 cpu-migrations # 0.448 K/sec 60 page-faults # 0.017 K/sec 6,076,570,590 cycles # 1.691 GHz 4,317,115,815 instructions # 0.71 insn per cycle 788,078,499 branches # 219.312 M/sec 29,054,771 branch-misses # 3.69% of all branches 31.398821987 seconds time elapsed  "});index.add({'id':11,'href':'/docs/getting-started/','title':"Getting Started",'content':""});index.add({'id':12,'href':'/docs/grain/cargo-bpf/','title':"Cargo Bpf",'content':""});index.add({'id':13,'href':'/docs/grain/ebpf/','title':"Ebpf",'content':""});index.add({'id':14,'href':'/docs/grain/intro/','title':"Intro",'content':""});index.add({'id':15,'href':'/docs/grain/userspace/','title':"Userspace",'content':""});index.add({'id':16,'href':'/docs/home/','title':"Home",'content':""});index.add({'id':17,'href':'/docs/shortcodes/','title':"Shortcodes",'content':""});index.add({'id':18,'href':'/docs/shortcodes/buttons/','title':"Buttons",'content':"Buttons Buttons are styled links that can lead to local page or external link.\nExample {{\u0026lt; button relref=\u0026#34;/\u0026#34; [class=\u0026#34;...\u0026#34;] \u0026gt;}}Get Home{{\u0026lt; /button \u0026gt;}} {{\u0026lt; button href=\u0026#34;https://github.com/alex-shpak/hugo-book\u0026#34; \u0026gt;}}Contribute{{\u0026lt; /button \u0026gt;}}  Get Home  Contribute  "});index.add({'id':19,'href':'/docs/shortcodes/columns/','title':"Columns",'content':"Columns Columns help organize shorter pieces of content horizontally for readability.\n{{\u0026lt; columns \u0026gt;}} \u0026lt;!--begin columns block --\u0026gt; # Left Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!--magic sparator, between columns --\u0026gt; # Mid Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!--magic sparator, between columns --\u0026gt; # Right Content Lorem markdownum insigne... {{\u0026lt; /columns \u0026gt;}} Example Left Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.  Mid Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter!  Right Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.   "});index.add({'id':20,'href':'/docs/shortcodes/expand/','title':"Expand",'content':"Expand Expand shortcode can help to decrease clutter on screen by hiding part of text. Expand content by clicking on it.\nExample Default {{\u0026lt; expand \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  Expand â†•  Markdown content Lorem markdownum insigne\u0026hellip;    With Custom Label {{\u0026lt; expand \u0026#34;Custom Label\u0026#34; \u0026#34;...\u0026#34; \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  Custom Label ...  Markdown content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.    "});index.add({'id':21,'href':'/docs/shortcodes/hints/','title':"Hints",'content':"Hints Hint shortcode can be used as hint/alerts/notification block.\nThere are 3 colors to choose: info, warning and danger.\n{{\u0026lt; hint [info|warning|danger] \u0026gt;}} **Markdown content** Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa {{\u0026lt; /hint \u0026gt;}} Example Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  "});index.add({'id':22,'href':'/docs/shortcodes/katex/','title':"Katex",'content':"KaTeX KaTeX shortcode let you render math typesetting in markdown document. See KaTeX\nExample {{\u0026lt; katex [display] [class=\u0026#34;text-center\u0026#34;] \u0026gt;}} x = \\begin{cases} a \u0026amp;\\text{if } b \\\\ c \u0026amp;\\text{if } d \\end{cases} {{\u0026lt; /katex \u0026gt;}}     Display Mode Example Here is some inline example: \\(\\pi(x)\\)  , rendered in the same line. And below is display example, having display: block \\[ x = \\begin{cases} a \u0026\\text{if } b \\\\ c \u0026\\text{if } d \\end{cases} \\]  Text continues here.\n"});index.add({'id':23,'href':'/docs/shortcodes/mermaid/','title':"Mermaid",'content':"Mermaid Chart Mermaid is library for generating svg charts and diagrams from text.\nExample {{\u0026lt; mermaid [class=\u0026#34;text-center\u0026#34;]\u0026gt;}} sequenceDiagram Alice-\u0026gt;\u0026gt;Bob: Hello Bob, how are you? alt is sick Bob-\u0026gt;\u0026gt;Alice: Not so good :( else is well Bob-\u0026gt;\u0026gt;Alice: Feeling fresh like a daisy end opt Extra response Bob-\u0026gt;\u0026gt;Alice: Thanks for asking end {{\u0026lt; /mermaid \u0026gt;}}     "});index.add({'id':24,'href':'/docs/shortcodes/tabs/','title':"Tabs",'content':"Tabs Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026#34;uniqueid\u0026#34; \u0026gt;}} {{\u0026lt; tab \u0026#34;MacOS\u0026#34; \u0026gt;}} # MacOS Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Linux\u0026#34; \u0026gt;}} # Linux Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Windows\u0026#34; \u0026gt;}} # Windows Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; /tabs \u0026gt;}} Example MacOS  MacOS This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n Linux  Linux This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n Windows  Windows This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n  "});index.add({'id':25,'href':'/categories/','title':"Categories",'content':""});index.add({'id':26,'href':'/docs/','title':"Docs",'content':""});index.add({'id':27,'href':'/','title':"InGRAINd",'content':"eBPF for Everyone Runtime security for containers InGRAINd helps you gather runtime security metrics from your Linux machines without modifying a single line of code.\nMake fine-grained rules about what your containerized services can or can\u0026rsquo;t do, and take immediate action.\nWrite your own modules for better observability using a cutting edge Rust-based toolchain that\u0026rsquo;s easy to use and blazing fast.\nSecure \u0026amp; Safe Both eBPF and Rust are designed for safe execution and protection against memory corruption vulnerabilities. With InGRAIN even you can write safe and secure modules that will never ruin your system.  Customize as you Wish Instead of treating the core of the system as black magic, InGRAINd provides easy to understand documentation for a variety of eBPF functionality, so you can extend and improve the data you rely on.  Designed for Real Life Because your time is your most expensive asset, we designed InGRAINd to make deployment easy and frictionless for monitoring VMs and containers. Kubernetes, GCP, AWS, Arm64, choose your own buzzword.   Why InGRAINd InGRAINd provides a cutting edge toolchain for monitoring your services in the cloud and on-premise using eBPF and Rust.\nStrengthen Security Detect and respond to against 0-day cryptominer and ransomware attacks  Reduce Risk Behavioural information about your containers has been a blindspot. Not anymore.  Automatic remediation Trigger automatic remediation for policy violations near real time.   "});index.add({'id':28,'href':'/tags/','title':"Tags",'content':""});})();