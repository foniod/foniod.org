'use strict';(function(){const b={cache:!0};b.doc={id:'id',field:['title','content'],store:['title','href']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/docs/configuration/auto-kill/',title:"Auto Kill",content:"Automatically kill programs InGRAINd can execute various commands to react to certain events with minimum overhead.\nBecause events are not intercepted, merely observed by the eBPF probe, InGRAIN cannot block a program from executing a certain action.\nHowever, using the events pipeline to filter and execute commands, InGRAIN can react to events quickly and reliably without involving other processing components. This means you fundamentally cannot stop a task from executing, but long-running processes can be killed.\nYou can configure this behaviour by adding the Exec step to your pipeline:\n[[pipeline.s3.steps]] type = \u0026quot;Exec\u0026quot; arguments = [\u0026quot;kill\u0026quot;, \u0026quot;-9\u0026quot;, \u0026quot;{ process_id }\u0026quot;] only_if = [ { key = \u0026quot;some_key\u0026quot;, regex = \u0026quot;prefix.*\u0026quot; } ]  Monitoring a directory For example, to stop someone editing your SSH keys using Vim, you can use the following configuration:\n[[probe]] pipelines = [\u0026quot;console\u0026quot;] [probe.config] type = \u0026quot;files\u0026quot; monitor_dirs = [\u0026quot;/home/user\u0026quot;] [[pipeline.s3.steps]] type = \u0026quot;Exec\u0026quot; command = [\u0026quot;kill\u0026quot;, \u0026quot;-9\u0026quot;, \u0026quot;{ process_id }\u0026quot;] only_if = [ { key = \u0026quot;process_str\u0026quot;, regex = \u0026quot;.*vim\u0026quot; }, { key = \u0026quot;path_str\u0026quot;, regex = \u0026quot;.*.ssh/id_.*\u0026quot; }, ]  "}),a.add({id:1,href:'/docs/configuration/backends/',title:"Backends",content:"Backends To export data from InGRAINd, you can use a number of backends.\nThese backends can process or forward the data in any way you want. Currently, the following integrations are available:\n  Console   S3   StatsD+   HTTP   The flush frequency of a backend can be controlled by using a Buffer pipeline step. If you don\u0026rsquo;t specify either interval_s or interval_ms in seconds or milliseconds, respectively, then the by default events are cached for 10 seconds before being forwarded to the backend.\nIf you don\u0026rsquo;t use histogram-type aggregations in your backend, you can disable it for some performance gains.\n[[pipeline.my_pipeline.steps]] type = \u0026quot;Buffer\u0026quot; interval_s = 30 enable_histograms = false  As a general rule, backends don\u0026rsquo;t handle errors in the upstream. If the upstream cannot accept a request for whatever reason, the events InGRAINd couldn\u0026rsquo;t deliver are not cached, they are simply dropped.\nConsole The Console backend is the simplest way to send events to another program. It will print JSON-formatted events, one event per line, on the standard output. You can enable it like this:\n[pipeline.console.config] backend = \u0026quot;Console\u0026quot;  It is great for interactive debugging purposes, or combining it with other tools as part of a log collector pipeline.\nThere\u0026rsquo;s no other configuration the Console backend receives, so if you want to process the events, you will need to redirect the InGRAINd output to your preferred destination.\nNote that the Console backend is separate from the logging facilities, which happen on the standard error pipe, and use a completely different infrastrucure.\nS3 The S3 backend will place JSON-formatted data dumps in an S3 bucket. To configure the AWS connection, you can use environment variables or credentials files as described in the Rusoto documentation To specify which bucket to use, set the AWS_S3_BUCKET environment variable.\nThe files will have a name like hostname_123456789123456789.json, where the long number is the UNIX nanosecond-precise timestamp.\nStatsD+ The StatsD+ backend will forward events from InGRAINd to compatible StatsD servers, such as Grafana, Graphite, or even DataDog. If the backend supports tags for events, they are also forwarded.\nYou can add a StatsD+ backend like so, with tagged events disabled:\n[pipeline.statsd.config] backend = \u0026quot;StatsD\u0026quot; use_tags = false  Configuration of the upstream server is done is done through 2 environment variables:\n STATSD_HOST: the hostname or IP address of the StatsD server STATSD_PORT: the port number of the StatsD server  Both of the variables above need to be set in order for the backend to start.\nHTTP The HTTP server works similarly to the S3 backend, except it can forward your events to any HTTP server using a POST request.\nFor instance, a realistic HTTP backend could look like so:\n[pipeline.http.config] backend = \u0026quot;http\u0026quot; uri = \u0026quot;http://example.redsift.com/insert\u0026quot; encoding = \u0026quot;json\u0026quot; [pipeline.http.config.headers] authorization = \u0026quot;Basic realm token\u0026quot; \u0026quot;custom-header\u0026quot; = \u0026quot;some value\u0026quot;  To use authenticated endpoints, you can specify extra headers to be sent in the [pipeline.http.config.headers] map, however, these need to be stored in the config file in unencrypted form.\nIn addition, the HTTP endpoint can encode its payload as Cap\u0026rsquo;n Proto in addition to JSON. The schema for the current version can be found in the repository .\nUsing Cap\u0026rsquo;n Proto lets you shave off significant amount of time when receiving and parsing InGRAINd events, at the cost of additional complexity.\n"}),a.add({id:2,href:'/docs/configuration/containers/',title:"Containers",content:"Containers Monitoring containerised workloads is usually not an easy thing to do. With InGRAINd, you can get the ID of the Docker container that\u0026rsquo;s hosting the applications with simply including the following in the Container step in your pipeline.\n[[pipeline.console.steps]] type = \u0026quot;Container\u0026quot;  This will add the docker_id tag to each event that comes from a container, allowing you to link them to a running Docker container.\nSince Kubernetes is based on Docker, this also allows you to monitor workloads in Kubernetes clusters.\nFor instance, when a container is tagged like the following,\n\u0026quot;docker_id\u0026quot;: \u0026quot;c746bf8f9aadb4d5a3577fb67f34029c07c03607a4979779854dd59f373ef5b8\u0026quot;  You can gather information about it just by using the usual Docker CLI:\n$ docker inspect c746bf8f9aadb4d5a3577fb67f34029c07c03607a4979779854dd59f373ef5b8  "}),a.add({id:3,href:'/docs/configuration/network/',title:"Network",content:"Network monitoring The network monitoring grain in InGRAINd collects network events straight from the kernel, unlike most network monitoring solutions. Because of this, InGRAINd can observe detailed statistics about the network behaviour of applications without impacting network throughput and performance.\nEnabling network monitoring for all network interfaces, therefore, is as easy as enabling the Network probe in config.toml:\n[[probe]] pipelines = [\u0026quot;console\u0026quot;] [probe.config] type = \u0026quot;Network\u0026quot;  The grain monitors all outgoing connections from the box, and will print the details of outgoing connections:\n[{\u0026quot;timestamp\u0026quot;:1582294577893714161, \u0026quot;kind\u0026quot;:13, \u0026quot;name\u0026quot;:\u0026quot;connection.out_count\u0026quot;, \u0026quot;measurement\u0026quot;:1, \u0026quot;tags\u0026quot;:{\u0026quot;s_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;s_port\u0026quot;:\u0026quot;45719\u0026quot;, \u0026quot;d_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;process_id\u0026quot;:\u0026quot;4878\u0026quot;, \u0026quot;process_str\u0026quot;:\u0026quot;Socket Thread\u0026quot;, \u0026quot;d_port\u0026quot;:\u0026quot;1313\u0026quot;}}]  The details of an outbound and inbound traffic is also clearly visible, even on localhost:\n[{\u0026quot;timestamp\u0026quot;:1582294577893874264, \u0026quot;kind\u0026quot;:9, \u0026quot;name\u0026quot;:\u0026quot;volume.out_byte\u0026quot;, \u0026quot;measurement\u0026quot;:0, \u0026quot;tags\u0026quot;:{\u0026quot;d_port\u0026quot;:\u0026quot;1313\u0026quot;, \u0026quot;d_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;process_str\u0026quot;:\u0026quot;Socket Thread\u0026quot;, \u0026quot;s_port\u0026quot;:\u0026quot;45719\u0026quot;, \u0026quot;s_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;process_id\u0026quot;:\u0026quot;4878\u0026quot;, \u0026quot;proto\u0026quot;:\u0026quot;tcp\u0026quot;}}] [{\u0026quot;timestamp\u0026quot;:1582294577893943829, \u0026quot;kind\u0026quot;:9, \u0026quot;name\u0026quot;:\u0026quot;volume.in_byte\u0026quot;, \u0026quot;measurement\u0026quot;:72, \u0026quot;tags\u0026quot;:{\u0026quot;s_port\u0026quot;:\u0026quot;8453\u0026quot;, \u0026quot;d_port\u0026quot;:\u0026quot;38834\u0026quot;, \u0026quot;d_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;s_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;proto\u0026quot;:\u0026quot;tcp\u0026quot;, \u0026quot;process_str\u0026quot;:\u0026quot;hugo\u0026quot;, \u0026quot;process_id\u0026quot;:\u0026quot;34081\u0026quot;}}]  The value of measurement is in bytes, and every single read() and write() system call can be observed for UDP and TCP traffic.\n"}),a.add({id:4,href:'/docs/configuration/osquery/',title:"Osquery",content:"OsQuery  OsQuery is an endpoint visibility solution originally developed at Facebook, and now maintained by The Linux Foundation.\nWhile OsQuery is most often deployed to monitor laptops and desktop computers, we included it in the default InGRAINd Docker images to collect dynamic configuration and runtime information about your environment.\nFor instance, you can use the OsQuery integration to report statistics about your processes CPU use periodically using the following configuration:\n[[probe]] pipelines = [\u0026quot;console\u0026quot;] [probe.config] type = \u0026quot;Osquery\u0026quot; interval_ms = 10000 [[probe.config.queries]] query = \u0026quot;SELECT user_time, name as process_str, pid as process_id from processes\u0026quot; name = \u0026quot;process_user_time\u0026quot; measurement = \u0026quot;user_time\u0026quot; measurement_type = \u0026quot;count\u0026quot; [[probe.config.queries]] query = \u0026quot;SELECT system_time, name as process_str, pid as process_id from processes\u0026quot; name = \u0026quot;process_system_time\u0026quot; measurement = \u0026quot;system_time\u0026quot; measurement_type = \u0026quot;count\u0026quot;  The config above will run the SELECT queries every 10 seconds.\nIn the emitted events, every column referenced in the SELECT statement will create a new tag. You can also specify which of the selected fields should be treated as a measurement, and the associated unit of measurement.\n"}),a.add({id:5,href:'/docs/configuration/statsd/',title:"Statsd",content:"StatsD Besides supporting StatsD as an upstream backend to which InGRAINd can send data, it can also act as a StatsD server that accepts metrics from applications and forwards them to another upstream.\nThis allows you to use only InGRAINd on your system as the component that collects and forwards system performance, security, and application metrics.\nAn example config file that provides a local a StatsD collector then forwards it to an upstream server would look like this:\n[[probe]] pipelines = [\u0026quot;statsd\u0026quot;] [probe.config] type = \u0026quot;StatsD\u0026quot; bind_address = \u0026quot;127.0.0.1:8125\u0026quot; flush_interval = \u0026quot;10000\u0026quot; [pipeline.statsd.config] backend = \u0026quot;StatsD\u0026quot; use_tags = false  To then run InGRAINd, you should make sure to set STATSD_HOST and STATSD_PORT variables that point to the upstream server.\n"}),a.add({id:6,href:'/docs/configuration/syntax/',title:"Syntax",content:"Configuration syntax The configuration format used by ingraind is TOML.\nThe primary goal of the configuration system is to set up the grains and the processing pipelines used by ingraind.\nThe TOML file has two sections: the probes, and the pipelines.\nProbes The probe array contains the configuration for the probes, and a single entry looks like this:\n[[probe]] pipelines = [\u0026quot;my_pipeline\u0026quot;, \u0026quot;another_pipeline\u0026quot;] [probe.config] type = \u0026quot;Files\u0026quot; monitor_dirs = [\u0026quot;/\u0026quot;] The probe has to specify a list of pipelines that will receive its data. The probe.config section configures the probe itself; the type attribute is mandatory, anything else is probe dependent.\nThe different brackets in [[probe]] and [probe.config] are intentional: [[probe]] means a new entry in the probe array, while [probe.config] means \u0026ldquo;the config attribute of the probe\u0026rdquo;.\nPipelines The pipelines are named sequences of actions. Some steps in the pipeline will have state, so be aware that multiple probes targeting the pipeline with the same name, will use the same instance of the pipeline.\nConfiguration of pipelines looks like this:\n[pipeline.my_pipeline.config] backend = \u0026quot;StatsD\u0026quot; use_tags = true [[pipeline.statsd.steps]] type = \u0026quot;Whitelist\u0026quot; allow = [\u0026quot;k1\u0026quot;, \u0026quot;k2\u0026quot;] [[pipeline.statsd.steps]] type = \u0026quot;AddSystemDetails\u0026quot; [[pipeline.statsd.steps]] type = \u0026quot;Buffer\u0026quot; interval_s = 30 The distinction between the [pipeline.statsd.config] and [[pipeline.statsd.steps]] are the same as previously.\nEvents generated by the probe will hit the first step in the pipeline. Steps are defined in sequence, and events will trickle through every step, unless they are filtered out.\nThe pipeline.name.config.backend specifies which backend is used to transmit or store the events after every step in the pipeline is complete, and is a mandatory attribute. Other attributes in the pipeline.name.config section are dependent on the given backend.\n"}),a.add({id:7,href:'/docs/deployment/ansible/',title:"Ansible",content:"Ansible InGRAINd provides Ansible roles in the repository that you can lift and integrate into your deployment systems.\nThe role installs OSQuery by default on compatible systems, which means you can use the InGRAINd - OSQuery bridge to gather a wide range of system statistics using a single configuration file .\nConfiguration To keep configuration as simple as possible, the role relies on the following variables :\ningraind_circleci_url ingraind_circleci_sha256 ingraind_http_api_key ingraind_http_uri  By default the agent will send events to an HTTP backend periodically.\nSystemD The Ansible role, by default, deploys a SystemD service file and configures it to use the configuration location for /etc/ingraind/ingraind.toml .\nKeeping up-to-date To keep InGRAINd up-to-date, we will reference the URL and hash of the latest stable release in the repository\u0026rsquo;s variables file , so you can synchronise the role and override the default variables in your deployment.\n"}),a.add({id:8,href:'/docs/deployment/kubernetes/',title:"Kubernetes",content:"Kubernetes Monitoring a Kubernetes cluster is easy based on the YAML files that are in the InGRAINd repository.\nYou can use the following containers built from the InGRAINd releases for various platforms:\n latest-gke: Google Container Optimized OS (COS) latest-amzn2: Amazon Linux 2 latest-fedora31: Fedora 31 latest-elrepo8: CentOS8/Epel latest-elrepo7: CentOS7/Epel latest-ubuntu-18.04: Ubuntu 18.04  For deploying InGRAINd on Google Kubernetes Engine, use the latest-gke flavor, targeting Container Optimized OS (COS).\nWhen using Amazon Elastic Kubernetes Service (EKS), use latest-amzn2, which also works on Amazon Linux VMs as a privileged Docker container.\nInGRAINd requires access to system folders and eBPF-related system calls, therefore it needs to run as a privileged container.\nTo deploy InGRAINd on Kubernetes, adjust the ingraind.yaml file with the correct flavor of the containers for your host operating system, and use the usual deployment ritual:\nkubectl apply -f config.yaml kubectl apply -f ingraind.yaml  Refer to the pages on configuration and the example config.toml for fine-tuning config.yaml.\n"}),a.add({id:9,href:'/docs/deployment/strategies/',title:"Strategies",content:"Deployment Strategies The best deployment strategy for your environment depends on a few factors. Whether you want to monitor containers, the orchestration service you\u0026rsquo;re running, and the amount of automation you already have, there are a few routes to go.\nAn abundance of containers To monitor containers across your fleet, you can use the native Kubernetes support. This comes packaged suitable for your environment and there\u0026rsquo;s no need to install drivers or kernel modules if you\u0026rsquo;re on one of the big cloud providers.\nA fleet of VMs To provision InGRAINd as part of your VM fleet, or Packer images, you\u0026rsquo;re best off taking inspiration from the Ansible rules, or using the integrations.\nAnsible integrates neatly with both Packer and Terraform through their modular environments.\n"}),a.add({id:10,href:'/docs/devel/internals/',title:"Internals",content:"How it all works  Build Build starts with build.rs going through all modules in the bpf/ directory, and:\n Compile all .c files with clang into BPF bytecode. Run bindgen for all structs, the names of which start with _data_ (e.g. _data_tcp_connect).  bpf_helpers.h is in the include directory, so bindgen can be run freely on all .h files under bpf/. This is quirky, but works.\nThe produced BPF bytecode ELF packages are embedded in the final binary using include_bytes! statements. The produced bindings are embedded using include! statements.\nRuntime Grains are self-contained monitors and reporters. Each grain can gather their own type of statistics about a particular aspect of the system\u0026rsquo;s operation. Grains need to manage any BPF modules they might be using. Every grain is coupled with a dedicated cloud-based analytics backend.\nBPF probes are using the kernel\u0026rsquo;s eBPF virtual machine to execute a safe bytecode directly in kernel-space. These modules can only interact with the outside world using well-defined interfaces, and cannot execute arbitrary system calls.\nThe BPF modules will send data to userland using perf_event ring-buffers. These ring-buffers are fixed size buffers with a size multiples of the platform native VMM page size (4k on x86/x64).\nImportant to note 2 things:\n The license of BPF modules needs to be GPL is we want to extract data from the kernel into userland through the perf_event interface. If the module\u0026rsquo;s version does not match the running kernel\u0026rsquo;s version number, the kernel will refuse to load the module. The workaround here is using 0xFFFFFFFE in the binary to stay compatible with gobpf. This version will be replaced runtime by redbpf.  After the BPF probes are parsed from the ELF files, the following syscalls are made, in order:\n bpf_create_map: All global data is stored in maps. These structures are allocated during parsing. bpf_prog_load: Load a program into the BPF VM, and initialise it bpf_attach_kprobe: Attach BPF probes to a syscall. Entry probes and return probes are possible, they will be called when entering or exiting a syscall, respectively. bpf_update_elem: the perf_event ringbuffers are initialised. This includes allocating a perf_reader object, which are used for userspace consumption of the bpf_perf_event_output calls in the probes.  Perf Events Ingraind uses the perf_event_open (2) interface to communicate with the kernel\u0026rsquo;s BPF VM.\nThe BPF modules will access the perf_event ring buffers through a BPF_MAP structure of type BPF_MAP_PERF_EVENT_ARRAY. The maps contain an fd that is keyed by the CPU id. Technically, multiple strategies are allowed for keying this map, but the most popular looks like setting up a separate ring buffer for every online single CPU.\nEvents are consumed using an epoll_wait loop, and read until exhaustion. The benefit of a single epoll_wait loop is that all the complex logic behind initialisation of different grains ultimately ends up allowing notifications through a single fd, including all network, and even perf_event buffers.\nELF parsing A thing to note here before I get into this, is how state is managed in the BPF VM. There\u0026rsquo;s no global state allowed, so anything that needs to be persisted between calls into the probe needs to go through BPF_MAP_.* structures through VM opcodes (#define\u0026rsquo;d as function calls, eg. update, delete, etc.).\nA corollary to this is that global state used in the C source code is stored in the ELF binary in named PROGBITS sections , then loaded and initialised to be BPF_MAPs by the loader as data. We load this into memory, treating it as configuration, then instruct the kernel to set up global state storage to get an fd in return. This fd can also be used to send data back and forth between kernel- and userspace in certain cases.\nIt gets interesting when these are referenced in code (functions). The compiler generates a REL section that links to the symbol table, and has an info field that is a link to the amended section of code. The offset field specifies the offset in bytes from the start of the section that needs to be modified. A relocation, strictly in the BPF context, is a rewrite instruction for a specific instruction, in a specific section, referencing a specific symbol.\nBecause data access is always through VM opcodes, the instruction at the offset location is\u0026hellip; something. We don\u0026rsquo;t actually care. Relocations tell us to\u0026hellip; do something with it.\nWe need to rewrite the instruction\u0026rsquo;s source register (src_reg) with BPF_PSEUDO_MAP_FD, and the immediate constant parameter (imm) with the fd of the map that\u0026rsquo;s referenced by the symbol.\nSo to recap, this is the workflow to deal with loading ELF files:\n Load the strings table Load the symbol table Parse all the sections Create BPF_MAPs from the maps/ sections to acquire fds Go through all code sections, and apply relocations such that:  Resolve all REL symbols into fds (through the symbol table and back again). Rewrite the instruction at specified offset    "}),a.add({id:11,href:'/docs/devel/performance/',title:"Performance",content:"Performance The following measurements were done on an 8-core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz, Arch Linux, and ingraind @ 43281a7 .\nThe following command will produce the raw output:\ncargo build --release \u0026amp;\u0026amp; \\ sudo AWS_ACCESS_KEY_ID=x \\ AWS_SECRET_ACCESS_KEY=x \\ AWS_BUCKET=x \\ AWS_INTERVAL=30 \\ DNS_IF=wlp61s0 \\ RUST_BACKTRACE=1 ./target/release/ingraind \u0026amp; sleep 5 \\ \u0026amp;\u0026amp; (top -b -d 2 |grep ingraind) \u0026gt;top_log \u0026amp; \\ iperf3 -t 10 -b 10M -c localhost \u0026gt; iperf_log \\ \u0026amp;\u0026amp; sleep 1 \u0026amp;\u0026amp; iperf3 -t 10 -b 100M -c localhost \u0026gt;\u0026gt;iperf_log \\ \u0026amp;\u0026amp; sleep 1 \u0026amp;\u0026amp; iperf3 -t 10 -b 1000M -c localhost \u0026gt;\u0026gt;iperf_log \\ \u0026amp;\u0026amp; sleep 1 \u0026amp;\u0026amp; iperf3 -t 10 -b 10000M -c localhost \u0026gt;\u0026gt;iperf_log \\ \u0026amp;\u0026amp; pkill top \\ \u0026amp;\u0026amp; @ pkill ingraind  Looking through the logs, we can see that CPU use follows bandwidth:\n   Bandwidth CPU %     10M 1%   100M 4%   1000M 32%   10000M 98%     This is test only measures the TCPv4 throughput of the one process, but gives a good idea about scaling.\n"}),a.add({id:12,href:'/docs/devel/profiling/',title:"Profiling",content:"Profiling During development The recommended way to profile ingraind binaries is using perf. The default --release builds are not stripped, therefore it should be easy to analyse the results.\nsudo perf record ./target/release/ingraind sudo perf report  Docker If running in a container, the recommended way is to start ingraind, then attach perf, and look the results off the box.\nsudo docker run -d --name ingraind -e OPTION=value [...] --pid=host --net=host --privileged ingraind sudo perf record -a -p `pgrep ingraind`  Looking at the results in this scenario is a bit tricky, because we will need to tell perf where the binaries are located to resolve the symbols.\nThis can be done by starting an ingraind container on the box that we\u0026rsquo;re using for analysis (if different from the system where we collected the data), then using the merged overlay filesystem as a base for symbol resolution. Note, you will need to use the same container version, as the symbols will change between builds.\nThis can be easily done like so:\nexport VERSION=sha256_of_profiled_container docker run -d --rm --name ingraind -it ingraind:$VERSION /bin/sh export CONTAINER_HASH=$(docker inspect ingraind |grep MergedDir |sed 's;.*: \u0026quot;\\(.*\\)\u0026quot;,;\\1;') sudo perf report -f -i perf.data_docker --symfs /var/lib/docker/overlay2/$CONTAINER_HASH/merged  After you\u0026rsquo;re done, you can shut down the container.\ndocker stop ingraind  Stat To get detailed stats about the execution of ingraind, you can perf stat like so:\n$ perf stat -a -p `pgrep ingraind` Performance counter stats for process id '28037': 3593.405601 cpu-clock (msec) # 0.114 CPUs utilized 147,307 context-switches # 0.041 M/sec 1,611 cpu-migrations # 0.448 K/sec 60 page-faults # 0.017 K/sec 6,076,570,590 cycles # 1.691 GHz 4,317,115,815 instructions # 0.71 insn per cycle 788,078,499 branches # 219.312 M/sec 29,054,771 branch-misses # 3.69% of all branches 31.398821987 seconds time elapsed  "}),a.add({id:13,href:'/docs/getting-started/',title:"Getting Started",content:"Getting Started To get started with ingraind, you will need a Linux-based system. Generally, any recent release of a modern distribution will work fine.\nTo deploy on Kubernetes and on various cloud platforms, you will want to take a peek at our Kubernetes tutorial If you\u0026rsquo;re running Fedora 31, or Ubuntu 18.04, you will be able to get going using Docker and a configuration file.\nA configuration file will look like the snippet below. Name it config.toml.\n# Monitor network activity, both IPv4 and IPv6. [[probe]] pipelines = [\u0026quot;console\u0026quot;] [probe.config] type = \u0026quot;Network\u0026quot; # Log inbound DNS traffic. # This includes all answers to outbound UDP DNS queries. [[probe]] pipelines = [\u0026quot;console\u0026quot;] [probe.config] type = \u0026quot;DNS\u0026quot; interface = \u0026quot;wlp61s0\u0026quot; # Intercept TLS handshakes and log server name and cypher details. [[probe]] pipelines = [\u0026quot;console\u0026quot;] [probe.config] type = \u0026quot;TLS\u0026quot; interface = \u0026quot;wlp61s0\u0026quot; # Monitor access to /usr/bin by all processes. # This will log all applications started from that directory. [[probe]] pipelines = [\u0026quot;console\u0026quot;] [probe.config] type = \u0026quot;Files\u0026quot; monitor_dirs = [\u0026quot;/usr/bin\u0026quot;] # Add the Docker Container ID to all events observed in a container. [[pipeline.console.steps]] type = \u0026quot;Container\u0026quot; # Add system details to every log event. [[pipeline.console.steps]] type = \u0026quot;AddSystemDetails\u0026quot; # Group events for every second. Disable histogram aggregations. [[pipeline.console.steps]] type = \u0026quot;Buffer\u0026quot; interval_s = 1 enable_histograms = false # Print everything on the console in JSON format [pipeline.console.config] backend = \u0026quot;Console\u0026quot;  For an exhaustive list of grains and configuration options, look at the example configuration in the repository.\nDocker To start an ingraind Docker container on Ubuntu 18.04, use the following command line:\ndocker run -v $(pwd)/config.toml:/config/ingraind.toml --privileged --rm quay.io/redsift/ingraind:latest-ubuntu-18.04  For running on Fedora 31, you can use the following:\ndocker run -v $(pwd)/config.toml:/config/ingraind.toml --privileged --rm quay.io/redsift/ingraind:latest-fedora31  Build from scratch To get ingraind working on your workstation, you will need to start by installing a few packages and the Rust toolchain.\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh  Ubuntu On Ubuntu, the list of dependencies can be installed with apt.\napt-get -y install debhelper cmake libllvm9 llvm-9-dev libclang-9-dev \\ libelf-dev bison flex libedit-dev clang-format-9 \\ devscripts zlib1g-dev libfl-dev \\ pkg-config libssl-dev \\ curl wget \\ git \\ clang \\ capnproto  Fedora On Fedora, install dependencies using the following command.\nyum install -y clang-9.0.0 llvm-9.0.0 llvm-libs-9.0.0 llvm-devel-9.0.0 llvm-static-9.0.0 capnproto kernel kernel-devel elfutils-libelf-devel ca-certificates  Building After installing the dependencies, build ingraind with the usual build ritual.\ncargo build --release  And run it as root.\nsudo ./target/release/ingraind ./config.toml  If everything worked, you should start seeing output on the console from events happening on your system.\nTo get into more advanced topics, read the configuration pages.\n"}),a.add({id:14,href:'/docs/grain/cargo-bpf/',title:"Cargo Bpf",content:"cargo bpf Work in progress\n"}),a.add({id:15,href:'/docs/grain/ebpf/',title:"Ebpf",content:"eBPF Work in progress\u0026hellip;\n"}),a.add({id:16,href:'/docs/grain/intro/',title:"Intro",content:"Extending InGRAINd Work in progress\u0026hellip;\n"}),a.add({id:17,href:'/docs/grain/userspace/',title:"Userspace",content:"Userspace events Work in progress\u0026hellip;\n"}),a.add({id:18,href:'/docs/home/',title:"Home",content:""}),a.add({id:19,href:'/docs/shortcodes/',title:"Shortcodes",content:""}),a.add({id:20,href:'/docs/shortcodes/buttons/',title:"Buttons",content:"Buttons Buttons are styled links that can lead to local page or external link.\nExample {{\u0026lt; button relref=\u0026#34;/\u0026#34; [class=\u0026#34;...\u0026#34;] \u0026gt;}}Get Home{{\u0026lt; /button \u0026gt;}} {{\u0026lt; button href=\u0026#34;https://github.com/alex-shpak/hugo-book\u0026#34; \u0026gt;}}Contribute{{\u0026lt; /button \u0026gt;}}  Get Home  Contribute  "}),a.add({id:21,href:'/docs/shortcodes/columns/',title:"Columns",content:"Columns Columns help organize shorter pieces of content horizontally for readability.\n{{\u0026lt; columns \u0026gt;}} \u0026lt;!-- begin columns block --\u0026gt; # Left Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic sparator, between columns --\u0026gt; # Mid Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic sparator, between columns --\u0026gt; # Right Content Lorem markdownum insigne... {{\u0026lt; /columns \u0026gt;}} Example Left Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.  Mid Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter!  Right Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.   "}),a.add({id:22,href:'/docs/shortcodes/expand/',title:"Expand",content:"Expand Expand shortcode can help to decrease clutter on screen by hiding part of text. Expand content by clicking on it.\nExample Default {{\u0026lt; expand \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  Expand ↕  Markdown content Lorem markdownum insigne\u0026hellip;    With Custom Label {{\u0026lt; expand \u0026#34;Custom Label\u0026#34; \u0026#34;...\u0026#34; \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  Custom Label ...  Markdown content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.    "}),a.add({id:23,href:'/docs/shortcodes/hints/',title:"Hints",content:"Hints Hint shortcode can be used as hint/alerts/notification block.\nThere are 3 colors to choose: info, warning and danger.\n{{\u0026lt; hint [info|warning|danger] \u0026gt;}} **Markdown content** Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa {{\u0026lt; /hint \u0026gt;}} Example Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  "}),a.add({id:24,href:'/docs/shortcodes/katex/',title:"Katex",content:"KaTeX KaTeX shortcode let you render math typesetting in markdown document. See KaTeX Example {{\u0026lt; katex [display] [class=\u0026#34;text-center\u0026#34;] \u0026gt;}} x = \\begin{cases} a \u0026amp;\\text{if } b \\\\ c \u0026amp;\\text{if } d \\end{cases} {{\u0026lt; /katex \u0026gt;}}     Display Mode Example Here is some inline example: \\(\\pi(x)\\)  , rendered in the same line. And below is display example, having display: block \\[ x = \\begin{cases} a \u0026\\text{if } b \\\\ c \u0026\\text{if } d \\end{cases} \\]  Text continues here.\n"}),a.add({id:25,href:'/docs/shortcodes/mermaid/',title:"Mermaid",content:"Mermaid Chart  Mermaid is library for generating svg charts and diagrams from text.\nExample {{\u0026lt; mermaid [class=\u0026#34;text-center\u0026#34;]\u0026gt;}} sequenceDiagram Alice-\u0026gt;\u0026gt;Bob: Hello Bob, how are you? alt is sick Bob-\u0026gt;\u0026gt;Alice: Not so good :( else is well Bob-\u0026gt;\u0026gt;Alice: Feeling fresh like a daisy end opt Extra response Bob-\u0026gt;\u0026gt;Alice: Thanks for asking end {{\u0026lt; /mermaid \u0026gt;}}     "}),a.add({id:26,href:'/docs/shortcodes/tabs/',title:"Tabs",content:"Tabs Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026#34;uniqueid\u0026#34; \u0026gt;}} {{\u0026lt; tab \u0026#34;MacOS\u0026#34; \u0026gt;}} # MacOS Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Linux\u0026#34; \u0026gt;}} # Linux Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Windows\u0026#34; \u0026gt;}} # Windows Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; /tabs \u0026gt;}} Example MacOS MacOS This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nLinux Linux This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nWindows Windows This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n "}),a.add({id:27,href:'/landing/about/',title:"About",content:" ingraind and RedBPF are being developed by a community of individuals and companies from across the globe. The project is used in industries like security, gaming, or blockchain. ingraind was originally developed by Red Sift .\nTo learn more about contributing , please consult our documentation.\n"}),a.add({id:28,href:'/docs/',title:"Docs",content:""}),a.add({id:29,href:'/landing/',title:"Landings",content:""})})()